{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animal Shelter Intake Analysis in Austin, TX by Location\n",
    "## Data Preparation\n",
    "#### Stephen Schadt, Group 2 Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Google API Key\n",
    "from config import gkey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build animal / location dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Filtered Dataframe: Only intakes from 1/1/16, 12/1/16, 6/1/17, or 9/1/17 and forward \n",
    "#  (depending on how many API calls we can make)\n",
    "#\n",
    "\n",
    "# *** Below datasets contain larger datasets and should only be loaded if you have ample API calls to make against Google Maps API ***\n",
    "# df_intakes_2016_and_on = pd.read_csv('raw data/Austin_Animal_Center_Intakes_2016_and_on.csv', encoding='latin-1')\n",
    "# df_intakes_2017_and_on = pd.read_csv('raw data/Austin_Animal_Center_Intakes_2017_and_on.csv', encoding='latin-1')\n",
    "# df_intakes_2017_and_on = pd.read_csv('raw data/Austin_Animal_Center_Intakes_092017_and_on.csv', encoding='latin-1')\n",
    "\n",
    "# *** Below dataset only contains 1000ish records - use this one for testing purposes ***\n",
    "df_intakes_2017_and_on = pd.read_csv('raw data/Austin_Animal_Center_Intakes_2017-11_and_on.csv', encoding='latin-1')\n",
    "\n",
    "# Create clean dataframe to populate only rows with applicable addresses\n",
    "df_intakes_clean = pd.DataFrame(columns=[\"DateTime\", \"Found Address\", \"Intake Type\", \"Intake Condition\",\n",
    "                                        \"Animal Type\", \"Sex upon Intake\", \"Age upon Intake\", \"Breed\", \"Color\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length of dataset: {len(df_intakes_2017_and_on)}\")\n",
    "df_intakes_2017_and_on.head(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# *********************************************\n",
    "# *** Function to clean address column data ***\n",
    "# *********************************************\n",
    "def clean_address(addr):\n",
    "    '''\n",
    "    Function: clean_address\n",
    "    Argument: address\n",
    "    Return values: tuple final address (string), is_full_address (boolean)\n",
    "    '''\n",
    "    # variable determining whether or not this is a full address (defaults to False)\n",
    "    is_full_address = False\n",
    "\n",
    "    # Initialize address variable by cleaning off the (TX) part\n",
    "    addressclean = addr.replace(\" (TX)\",\"\")\n",
    "\n",
    "    # Split the address from the city\n",
    "    address = addressclean.split(\" in \")\n",
    "\n",
    "    # Clean up address\n",
    "    address_words = addressclean.split(\" \")\n",
    "\n",
    "    # First find out if this address is not applicable\n",
    "    if addressclean == \"Outside Jurisdiction\":\n",
    "        address_final = \"NA\"\n",
    "    \n",
    "    # Next, find out if this is an actual street address\n",
    "    elif (len(address) > 1):\n",
    "        is_full_address = True\n",
    "\n",
    "        # Street address (raw)\n",
    "        address_street = address[0]\n",
    "        address_city = address[1]\n",
    "        \n",
    "        # Clean up addresses with \"/\" characters into [street1 and street2] syntax\n",
    "        address_corner = address_street.split(\"/\")\n",
    "        if len(address_corner) > 1:\n",
    "            address_street = f\"{address_corner[0]} and {address_corner[1]}\"\n",
    "        else:\n",
    "            address_street = address_corner[0]\n",
    "            \n",
    "        address_final = f\"{address_street},{address_city},TX\"\n",
    "        \n",
    "    # Finally, for non-address strings...single-city listing\n",
    "    else:\n",
    "        address_final = f\"{addressclean},TX\"\n",
    "        \n",
    "    return (address_final, is_full_address)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Loop through last-1-year or last-2-years dataset, and only insert rows with clean addresses into clean dataset\n",
    "#\n",
    "for index, row in df_intakes_2017_and_on.iterrows():\n",
    "    # Call function to clean up address into something we can pass to Google API\n",
    "    address_tuple = clean_address(row[\"Found Location\"])\n",
    "    address = address_tuple[0]\n",
    "    is_full_address = address_tuple[1]\n",
    "    \n",
    "    if address == \"NA\":\n",
    "        print(\"Outside jurisdiction - skipping\")\n",
    "        continue\n",
    "    elif is_full_address == False:\n",
    "        print(\"No actual address - skipping\")\n",
    "        continue\n",
    "    else:\n",
    "        # Fill empty \"clean\" dataframe with rows we actually want to process\n",
    "        df_intakes_clean = df_intakes_clean.append({\"DateTime\": row[\"DateTime\"],\n",
    "                                \"Found Address\": address,\n",
    "                                \"Intake Type\": row[\"Intake Type\"],\n",
    "                                \"Intake Condition\": row[\"Intake Condition\"],        \n",
    "                                \"Animal Type\": row[\"Animal Type\"],\n",
    "                                \"Sex upon Intake\": row[\"Sex upon Intake\"],\n",
    "                                \"Age upon Intake\": row[\"Age upon Intake\"],\n",
    "                                \"Breed\": row[\"Breed\"],\n",
    "                                \"Color\": row[\"Color\"]}, ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cleaned dataset\n",
    "print(f\"Length of entire dataset: {len(df_intakes_clean)}\")\n",
    "df_intakes_clean[\"Intake Type\"].value_counts()\n",
    "df_intakes_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Maps API integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create summary dataframe to house address, lat, long, and boolean indicating if this pet lived in a home\n",
    "df_summary = pd.DataFrame(columns=[\"Address\", \"Latitude\", \"Longitude\", \"Pet at Home\", \"Animal Type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function and For-loop to grab lat/lng from Google API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If we have already populated the summary dataframe, drop any rows where Lat/Long values are zero, \n",
    "#  so appending below will be clean\n",
    "df_summary = df_summary[df_summary.Latitude != 0]\n",
    "\n",
    "# Visualize the trimmed dataframe\n",
    "print(f\"Length of dataset: {len(df_summary)}\")\n",
    "df_summary.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **************************************************************\n",
    "# *** Function to pull lat / lng values from Google Maps API ***\n",
    "# **************************************************************\n",
    "def get_lat_long(address):\n",
    "    '''\n",
    "    Function: get_lat_long\n",
    "    Purpose:  Get lat and long codes from Google maps API, given an address string\n",
    "    Argument: address\n",
    "    Returns:  lat, long values\n",
    "    '''\n",
    "    # Create endpoint URL\n",
    "    endpoint_url = f\"https://maps.googleapis.com/maps/api/geocode/json?address={address}&key={gkey}\"\n",
    "\n",
    "    # Run request to grab the JSON at the requested URL\n",
    "    google_api_json = requests.get(endpoint_url).json()\n",
    "\n",
    "    # Append the lat/lng to the appropriate columns (use try / except to skip addresses with errors)\n",
    "    try: \n",
    "        lat = google_api_json[\"results\"][0][\"geometry\"][\"location\"][\"lat\"]\n",
    "        lng = google_api_json[\"results\"][0][\"geometry\"][\"location\"][\"lng\"]\n",
    "        retval = (lat, lng)\n",
    "\n",
    "    except IndexError:\n",
    "        retval = (0, 0)\n",
    "\n",
    "    return retval\n",
    "# Initialize loop variables\n",
    "row_count = 0 \n",
    "processed_addresses = []\n",
    "\n",
    "#\n",
    "# Loop through cleaned dataset and determine lat/lng using Google maps geocoding API\n",
    "#\n",
    "# ** NOTE: this loop must not exceed 25,000 calls to the Google API in a 24 hour period, per the Google free API terms ***\n",
    "#\n",
    "for index, row in df_intakes_clean.iterrows():\n",
    "    row_count += 1\n",
    "    \n",
    "    # Set address and pet_at_home boolean variable\n",
    "    addr = row[\"Found Address\"]\n",
    "    pet_at_home = False\n",
    "    \n",
    "    # If we've already done a lookup for this address, no need to call Maps API\n",
    "    if (addr in processed_addresses):\n",
    "        print(f\"Address already processed: {addr}\")\n",
    "        continue\n",
    "    else:\n",
    "        # Verify if this address already has a lat/long value in the table. If so, continue. \n",
    "        is_address_in_df = df_summary[df_summary.Address == addr].count()[\"Address\"]\n",
    "       \n",
    "        # If this address isn't already in the dataframe, call Google API to populate lat/lon\n",
    "        if (is_address_in_df == 0):\n",
    "            print(f\"New address being processed: {addr}: {str(row_count)}\")\n",
    "            (latitude, longitude) = get_lat_long(addr)\n",
    "            \n",
    "            # Append to addresses array to mark this address as processed\n",
    "            processed_addresses.append(addr)\n",
    "        else:\n",
    "            # Address was found, but the Latitude value is populated\n",
    "            print(f\"Address already populated: {addr}\")\n",
    "            continue\n",
    "       \n",
    "    # Set variables for \"Pet at Home\", \"Animal Type\"\n",
    "    animal_type = row[\"Animal Type\"]\n",
    "    if row[\"Intake Type\"] == \"Owner Surrender\" or row[\"Intake Type\"] == \"Euthanasia Request\" or row[\"Intake Type\"] == \"Public Assist\":\n",
    "        pet_at_home = True\n",
    "\n",
    "    # Append values to our summary dataframe\n",
    "    df_summary = df_summary.append({\"Address\": addr,\n",
    "                                    \"Latitude\": latitude,\n",
    "                                    \"Longitude\": longitude,\n",
    "                                    \"Pet at Home\": pet_at_home,\n",
    "                                    \"Animal Type\": animal_type},\n",
    "                                    ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length of summary dataset: {len(df_summary)}\")\n",
    "df_summary.head(50)\n",
    "\n",
    "# Save the DataFrame as a csv\n",
    "df_summary.to_csv(\"animal_shelter_analysis_summary_clean_LocationData.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create summary dataframes: 2016 to Present and Animals from Homes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create filtered datasets (animals in homes, cats, dogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Filter original dataframe into smaller datasets ***\n",
    "\n",
    "# All intakes not 'Wildlife' or 'Stray' Intake Type: includes \"Intake Type\" of:\n",
    "#     - Euthanasia request\n",
    "#     - Owner surrender\n",
    "#     - Public assist\n",
    "df_animals_homes = df_intakes_clean.loc[((df_intakes_clean[\"Intake Type\"] ==\"Owner Surrender\") | \n",
    "                                         (df_intakes_clean[\"Intake Type\"] == \"Euthanasia Request\") |\n",
    "                                         (df_intakes_clean[\"Intake Type\"] == \"Public Assist\")),]\n",
    "\n",
    "# Dogs only\n",
    "df_animals_dogs = df_intakes_clean.loc[(df_intakes_clean[\"Animal Type\"] ==\"Dog\"),]\n",
    "\n",
    "# Cats only \n",
    "df_animals_cats = df_intakes_clean.loc[(df_intakes_clean[\"Animal Type\"] ==\"Cat\"),]\n",
    "\n",
    "# Visualize homes dataset\n",
    "df_animals_homes.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_animals_dogs.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strays\n",
    "df_animals_strays = df_intakes_clean.loc[(df_intakes_clean[\"Intake Type\"] ==\"Stray\"),]\n",
    "print(f\"Length of strays dataset: {len(df_animals_strays)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create filtered dataframes of unique address lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate address counts for master dataset\n",
    "address_counts_all = df_intakes_clean[\"Found Address\"].value_counts()\n",
    "df_address_counts_all = pd.Series.to_frame(address_counts_all).reset_index()\n",
    "df_address_counts_all = df_address_counts_all.rename(columns={'index': 'Address', 'Found Address': 'Count'})\n",
    "df_address_counts_all.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create cleaned dataframe each filtered addresses dataset\n",
    "def convert_address_counts_to_df(address_counts):\n",
    "    '''\n",
    "    Function: convert_address_counts_to_df\n",
    "    Description: Convert address value counts to dataframe\n",
    "    Arguments: Series\n",
    "    Returns:  Dataframe\n",
    "    '''\n",
    "    df_address_counts = pd.Series.to_frame(address_counts).reset_index()\n",
    "    df_address_counts = df_address_counts.rename(columns={'index': 'Address', 'Found Address': 'Count'})\n",
    "    return df_address_counts\n",
    "\n",
    "# Create pets-in-homes-specific counts dataframe\n",
    "address_counts_homes = df_animals_homes[\"Found Address\"].value_counts()\n",
    "df_address_counts_homes = convert_address_counts_to_df(address_counts_homes)\n",
    "\n",
    "# Create dogs-specific counts dataframe\n",
    "address_counts_dogs = df_animals_dogs[\"Found Address\"].value_counts()\n",
    "df_address_counts_dogs = convert_address_counts_to_df(address_counts_dogs)\n",
    "\n",
    "# Create cats-specific counts dataframe \n",
    "address_counts_cats = df_animals_cats[\"Found Address\"].value_counts()\n",
    "df_address_counts_cats = convert_address_counts_to_df(address_counts_cats)\n",
    "\n",
    "# Create strays-specific counts dataframe \n",
    "address_counts_strays = df_animals_strays[\"Found Address\"].value_counts()\n",
    "df_address_counts_strays = convert_address_counts_to_df(address_counts_strays)\n",
    "\n",
    "# Visualize Strays address dataframe\n",
    "df_address_counts_strays.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize pets-in-homes addresses counts\n",
    "df_address_counts_homes.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create filtered summary dataframes with only valid Latitude/Longitude values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All animals\n",
    "df_animals_summary_all = df_summary.loc[(df_summary[\"Latitude\"] != 0),]\n",
    "\n",
    "# All animals in homes\n",
    "df_animals_summary_homes = df_summary.loc[(df_summary[\"Pet at Home\"] == True) &\n",
    "                                                         (df_summary[\"Latitude\"] != 0),]\n",
    "\n",
    "# Dogs only\n",
    "df_animals_summary_dogs = df_summary.loc[(df_summary[\"Animal Type\"] == \"Dog\") &\n",
    "                                                         (df_summary[\"Latitude\"] != 0),]\n",
    "\n",
    "# Cats only \n",
    "df_animals_summary_cats = df_summary.loc[(df_summary[\"Animal Type\"] == \"Cat\") & \n",
    "                                                         (df_summary[\"Latitude\"] != 0),]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize filtered dataframes\n",
    "print(f\"Length of 'All Animals' summary dataframe: {len(df_animals_summary_all)}\")\n",
    "print(f\"Length of 'Animals in Homes' summary dataframe: {len(df_animals_summary_homes)}\")\n",
    "df_animals_summary_all.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_address_counts_cats.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge intake address counts into summary dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge address count into master summary dataset\n",
    "df_summary_all = pd.merge(df_animals_summary_all, df_address_counts_all, on=\"Address\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export and visualize summary of all address counts\n",
    "df_summary_all.to_csv('raw data/animal_shelter_analysis_address_counts_ALL.csv', encoding='latin-1', index=False)\n",
    "df_summary_all.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge address count into pets-in-homes dataset\n",
    "df_summary_homes = pd.merge(df_animals_summary_homes, df_address_counts_homes, on=\"Address\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export and visualize summary of all address counts\n",
    "df_summary_homes.to_csv('raw data/animal_shelter_analysis_address_counts_HOMES.csv', encoding='latin-1', index=False)\n",
    "df_summary_homes.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge address count into dogs & cats dataset\n",
    "df_summary_dogs = pd.merge(df_animals_summary_dogs, df_address_counts_dogs, on=\"Address\")\n",
    "df_summary_cats = pd.merge(df_animals_summary_cats, df_address_counts_cats, on=\"Address\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export and visualize summary of Dogs address counts\n",
    "df_summary_dogs.to_csv('raw data/animal_shelter_analysis_address_counts_DOGS.csv', encoding='latin-1', index=False)\n",
    "df_summary_dogs.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export and visualize summary of Cats address counts\n",
    "df_summary_cats.to_csv('raw data/animal_shelter_analysis_address_counts_CATS.csv', encoding='latin-1', index=False)\n",
    "df_summary_cats.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge address count into strays dataset\n",
    "df_summary_strays = pd.merge(df_summary, df_address_counts_strays, on=\"Address\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Export and visualize summary of Dogs address counts\n",
    "df_summary_strays.to_csv('raw data/animal_shelter_analysis_address_counts_STRAYS.csv', encoding='latin-1', index=False)\n",
    "df_summary_strays.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes for plotting number of veterinarians vs. number of pet intakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add necessary column to plotting datasets\n",
    "df_animals_summary_all[\"Vet Count\"] = \"\"\n",
    "df_animals_summary_homes[\"Vet Count\"] = \"\"\n",
    "df_animals_summary_dogs[\"Vet Count\"] = \"\"\n",
    "df_animals_summary_cats[\"Vet Count\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Google API key value\n",
    "from config import gkey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through dataset and assign Vet count values by calling Google Radarsearch API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_animals_summary_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter\n",
    "row_count = 0\n",
    "\n",
    "# Loop through and run Google search to get all banks in 5 mile radius (8000 meters)\n",
    "for index, row in df_animals_summary_all.iterrows():\n",
    "    \n",
    "    # Create endpoint url using Google Places Radar and the lat/lng we identified earlier\n",
    "    #  - Radius search of roughly 1 mile\n",
    "    #  - Places type \"veterinary_care\" only\n",
    "    target_url =f\"https://maps.googleapis.com/maps/api/place/radarsearch/json?location={row['Latitude']},{row['Longitude']}&radius=1700&type=veterinary_care&key={gkey}\"\n",
    "\n",
    "    # This link helps to handily see the JSON generated for each query\n",
    "    print(f\"Now retrieving address #{row_count}: {df_animals_summary_all.loc[index]['Address']}\")\n",
    "    row_count += 1 \n",
    "    \n",
    "    # Run request to retrieve JSON from target URL (only if it hasn't been set yet)\n",
    "    if df_animals_summary_all.loc[index]['Vet Count'] == 0 or df_animals_summary_all.loc[index]['Vet Count'] == \"\":\n",
    "        vet_data = requests.get(target_url).json()\n",
    "        \n",
    "        # Retrieve vet count via number of results within the radius (2500 meters)\n",
    "        vet_count = len(vet_data[\"results\"])  \n",
    "        print(f\"Final Vet Count for address '{row['Address']}': {str(vet_count)}\")\n",
    "        print(\"\")    \n",
    "    \n",
    "        # Store the vet count into the Data Frame\n",
    "        df_animals_summary_all.set_value(index, \"Vet Count\", vet_count)\n",
    "    else:\n",
    "        print(f\"Vet Count already set for this address: {row['Address']}\")\n",
    "        \n",
    "    # Reset vet_count, so a previous record cannot influence a later one\n",
    "    vet_count = 0\n",
    "\n",
    "# Visualize the new dataset\n",
    "df_animals_summary_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to CSV\n",
    "df_animals_summary_all.to_csv('raw data/animal_shelter_analysis_with_Vet_data.csv', encoding='latin-1', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add number of intake addresses within each vet's lat/long combination to dataframe\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new tracking column for number of intakes within radius\n",
    "df_animals_summary_all[\"Intakes within Radius\"] = \"\"\n",
    "\n",
    "# Function to calculate if a given lat/long point is contained in the Google place's kilometer radius\n",
    "def is_location_within_1700meters(check_point_lat, check_point_long, center_point_lat, center_point_long, radius_km):\n",
    "    '''\n",
    "    Function: is_location_within_1700meters\n",
    "    Purpose:  Given lat long values for center point and check point, figure out whether or not check points are within\n",
    "                X kilometers (in our case, 1.7)\n",
    "    '''\n",
    "    \n",
    "    km_lat = 40000 / 360\n",
    "    km_lng = math.cos(math.pi * center_point_lat/180) * km_lat\n",
    "    dst_x = math.fabs(center_point_long - check_point_long) * km_lng\n",
    "    dst_y = math.fabs(center_point_lat - check_point_lat) * km_lat\n",
    "    \n",
    "    return math.sqrt(dst_x * dst_x + dst_y * dst_y) <= radius_km;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Radius should be 1.7km, to match 1700 meter Google Radarsearch lookup radius\n",
    "radius = 1.7 \n",
    "\n",
    "# Loop through dataset and assign how many intake locations are within given lat/long combination\n",
    "row_count = 0\n",
    "for index, row in df_animals_summary_all.iterrows():\n",
    "    # This link helps to handily see the JSON generated for each query\n",
    "    print(f\"Now retrieving address #{row_count}: {df_animals_summary_all.loc[index]['Address']}\")\n",
    "    row_count += 1 \n",
    "\n",
    "    # Reset inner loop count / boolean variables\n",
    "    is_found = False\n",
    "    num_found = 0\n",
    "    \n",
    "    # Loop through dataframe again, and determine how many lat/long combinations are within the current lat/long's 1700 meter radius\n",
    "    for i_inner, r_inner in df_animals_summary_all.iterrows():    \n",
    "        is_found = is_location_within_1700meters(r_inner[\"Latitude\"], r_inner[\"Longitude\"], row[\"Latitude\"], row[\"Longitude\"], radius)\n",
    "        if is_found == True:\n",
    "            num_found += 1\n",
    "            \n",
    "    # Set the number of found intakes for this center point \n",
    "    df_animals_summary_all.set_value(index, \"Intakes within Radius\", num_found)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to CSV, and visualize it\n",
    "df_animals_summary_all.to_csv('raw data/animal_shelter_analysis_with_VetAndRadius_data.csv', encoding='latin-1', index=False)\n",
    "df_animals_summary_all.head(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
